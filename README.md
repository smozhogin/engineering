# Конвейер Apache Airflow в задаче машинного обучения

## Архитектура проекта

### Расположение проекта в среде Linux Ubuntu 24.04

    app/ - директория для хранения разрабатываемых приложений в ОС
    ├── project/ - директория для хранения проектов
    │   └── medic_pipeline/ - корневая директория проекта medic_pipeline
    │       ├── config.ini - файл конфигурации с токенами (исключен из git)
    │       ├── dags/ - директория для хранения DAG-файлов
    │       │   └── pipeline_dag.py - DAG-файл конвейера
    │       ├── etl/ - директория для хранения ETL-файлов
    │       │   ├── data_loader.py - шаг 1 конвейера: загрузка данных
    │       │   ├── data_preprocessor.py - шаг 2 конвейера: предобработка данных
    │       │   ├── model_evaluator.py - - шаг 3 конвейера: обучение модели
    │       │   ├── model_trainer.py - шаг 4 конвейера: оценка модели
    │       │   └── results_keeper.py - шаг 5 конвейера: сохранение результатов
    │       ├── logger.py - логика работы логгера
    │       ├── logs/ - директория для хранения логов
    │       │   ├── data_loader.log - лог шага 1 конвейера: загрузка данных
    │       │   ├── data_preprocessor.log - лог шага 2 конвейера: предобработка данных
    │       │   ├── model_evaluator.log - лог шага 3 конвейера: обучение модели
    │       │   ├── model_trainer.log - лог шага 4 конвейера: оценка модели
    │       │   └── results_keeper.log - лог шага 5 конвейера: сохранение результатов
    │       ├── README.md - описание проекта medic_pipeline (текущий файл)
    │       ├── requirements.txt - перечень установленных пакетов виртуальной среды Python
    │       └── results/ - директория для персистентного хранения данных
    │           ├── logistic_regression_model.pkl - обученная модель логистической регрессии
    │           └── metrics.json - метрики в формате JSON
    └── venv/ - директория для хранения виртуальных сред Python
        └── medic/ - виртуальная среда Python для проекта medic_pipeline
            └── bin/ - бинарные файлы виртуальной среды
                ├── activate - активатор виртуальной среды
                ├── pip - установщик пакетов
                └── python - интерпретатор Python

### Используемые версии библиотек

- Виртуальная среда Python: 3.10.18
- Apache Airflow: 3.0.2

Также см. в файле requirements.txt.

### Шаги конвейера

    Загрузка данных --> Предобработка данных --> Обучение модели --> Оценка модели --> Сохранение результатов

1. Загрузка данных

   Производится загрузка данных по раковым заболеваниям пациентов. Данные сериализуются в формат JSON и через XCOM передаются на следующий шаг конвейера.
2. Предобработка данных

   Производится базовая предобработка данных: очищение записей с пропусками и нормализация признаков. Признаки **X** и целевые значения **y** передаются на следующий шаг конвейера с помощью XCOM через списки.
3. Обучение модели

   Производится обучение модели логистической регрессии на тестовых данных. Обученная модель сохраняется в персистентном хранилище на локальном диске в .pkl-файле. Путь к модели передается на следующий шаг конвейера через XCOM. Результаты разделения данных на обучающие и тестовые передаются посредством списков.
4. Оценка модели

   Производится предсказание тестовых значений и оценка результативности модели логистической регрессии через метрики **accuracy**, **precision**, **recall** и **f1_score**. Метрики сериализуются в формат JSON.
5. Сохранение результатов

   В Яндекс.Cloud было создано приложение **medic_pipeline**. По ClientID приложения запрашивается OAuth-токен. Данный токен прописывается в файле config.ini и используется в скрипте при сохранении файлов на удаленном диске.

   Результаты работы конвейера сохраняются на Яндекс.Диск по URL: https://disk.yandex.ru/d/ofnaZFAvsAnuIQ (общий доступ). По пути находятся:

   - Обученная модель логистической регрессии в файле .pkl;
   - Метрики в формате JSON.

**ВАЖНО:** Целью работы является не построение идеальной модели машинного обучения, а создание конвейера в рамках предмета инжиниринга данных. Данное допущение подразумевает минимальную обработку данных, обучение, оценку модели и сохранение результатов с целью демонстрации работы конвейера.

### Обработка ошибок

В каждом ETL-скрипте вызывается обработка ошибок через блоки **try-except**. Все ошибки сохраняются в логи. Подробнее, в секции логирования.

### Логирование

Логирование производится через модуль **logging**. В директории **logs** производится сохранение логов в формате:

    [ГГГГ-ММ-ДД ЧЧ:ММ:СС,XXX] - [наименование скрипта для шага конвейера] - INFO - Запуск шага [N] конвейера: [Наименование шага]
    [ГГГГ-ММ-ДД ЧЧ:ММ:СС,XXX] - [наименование скрипта для шага конвейера] - INFO - Завершение шага [N] конвейера: [Наименование шага]

При возникновении ошибки в лог передается сообщение в формате:

    [ГГГГ-ММ-ДД ЧЧ:ММ:СС,XXX] - [наименование скрипта для шага конвейера] - ERROR - При выполнении шага [N] конвейера: [Наименование шага] произошла ошибка - [Вывод ошибки]

При достижении размера лога в 5 Мб производится запись в новый файл лога. Максимальное количество файлов для логирования под каждый шаг конвейера - 3. После достижения максимального количества файлов логирования производится перезапись первого файла лога. И далее по кругу.

## Запуск проекта из Docker-контейнера
1. Скачиваем из репозитория DockerHub образ Docker

        docker login
        docker pull smozhogin/engineering_image:1.0.X
2. Создаем Docker-контейнер и запускаем в интерактивном режиме

        docker run -it -e LC_ALL=ru_RU.UTF-8 --gpus all --name engineering --hostname engineering -p 8080:8080 engineering_image:1.0.X
        docker start -ai engineering # Для запуска существующего контейнера
3. Активируем виртуальную среду

        source /app/venv/medic/bin/activate
4. Запускаем Apache Airflow

        airflow standalone
5. В браузере на хостовой машине переходим по URL  
   **Логин: admin, пароль: 123**

        http://localhost:8080/dags/Medic_Pipeline
6. Запускаем DAG на исполнение
